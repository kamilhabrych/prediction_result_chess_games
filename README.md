# Predicting results of chess games using Decision Tree, Random Forest and XGBoost

(ENG) Code from my Engineering Thesis called "APPLICATION OF MACHINE LEARNING TO CHESS GAME ANALYSIS"

Abstract:

This paper presents the definition of machine learning as well as its application to the analysis of historical chess play. The selected algorithms that were used to perform the analy- sis are described. Then the contents of the datasets were described and prepared for further work. The next stage of the work was a brief presentation of the Exploratory Data Analysis (EDA) along with an analysis of Elo ranking theory. In the practical part, the datasets were divided into training set (90%) and test set (10%). Lazy Predict test was performed to find the best classifier, then prediction results were presented using two metrics: accuracy and F1- score, for classifiers: Decision Tree, Random Forest and XGBoost. The best prediction score in the paper for the entire dataset is 60.94% for XGBoost classifier. In a later stage, the per- formance of the model was tested on other datasets and an analysis of the effect of individual features on the prediction score was performed. The paper concludes with a comparison with other similar works and conclusions.

(PL)

# Prognozowanie wyników partii szachowych

Kod pochodzi z mojej pracy inżynierskiej pt.: "ZASTOSOWANIE UCZENIA MASZYNOWEGO DO ANALIZY GRY W SZACHY"

Streszczenie:

W pracy przedstawiono definicję uczenia maszynowego jak i zastosowania go do anali- zy gry w szachy w historii. Opisano wybrane algorytmy, które zostały wykorzystane do prze- prowadzenia analizy. Następnie opisano zawartość zbiorów danych oraz przygotowano je do dalszej pracy. Kolejnym etapem pracy było krótkie przedstawienie badania eksploracyjnego wraz z analizą teorii rankingu Elo. W części praktycznej podzielono zbiory danych na zbiór treningowego (90%) oraz testowy (10%). Wykonano badanie wstępne w celu znalezienia naj- lepszego klasyfikatora, następnie przedstawiono wyniki predykcji przy pomocy dwóch me- tryk: dokładności (accuracy) oraz F1-score, dla klasyfikatorów: Drzewa decyzyjnego (Deci- sion Tree), lasu losowego (Random Forest) oraz XGBoost. Najlepszy wynik predykcji w pra- cy dla całego zbioru danych wynosi 60,94% dla klasyfikatora XGBoost. W późniejszym eta- pie sprawdzono działanie modelu na innych zbiorach danych oraz przeprowadzono analizę wpływu poszczególnych cech na wynik predykcji. Praca kończy się porównaniem z innymi, podobnymi pracami oraz wnioskami.
